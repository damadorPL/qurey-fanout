{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb1IuV7gH__b",
        "outputId": "27d9b541-5a63-4072-f27c-676658a5a670"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Gemini Query Fanout - Google Colab Version\n",
        "This script generates 10 semantically related questions from a keyword using Gemini\n",
        "Then uses Google embeddings and cosine similarity to rank and return the top N most relevant questions\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "def get_gemini_api_key():\n",
        "    \"\"\"Get Gemini API key from Google Colab secrets\"\"\"\n",
        "    try:\n",
        "        api_key = userdata.get(\"gemini_api\")\n",
        "        return api_key\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error getting API key from Colab secrets: {e}\")\n",
        "        print(\n",
        "            \"Please add 'gemini_api' to your Colab secrets (üîë icon in the left sidebar)\"\n",
        "        )\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_gemini_embeddings(texts, api_key):\n",
        "    \"\"\"\n",
        "    Get embeddings from Google Gemini API for a list of texts\n",
        "\n",
        "    Args:\n",
        "        texts: List of text strings to embed\n",
        "        api_key: Gemini API key\n",
        "\n",
        "    Returns:\n",
        "        List of embeddings or None if failed\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    print(f\"üîç Getting Gemini embeddings for {len(texts)} texts...\")\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-embedding-001:embedContent?key={api_key}\"\n",
        "\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "        data = {\"model\": \"gemini-embedding-001\", \"content\": {\"parts\": [{\"text\": text}]}}\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=data, timeout=60)\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "\n",
        "            if \"embedding\" in result and \"values\" in result[\"embedding\"]:\n",
        "                embedding = result[\"embedding\"][\"values\"]\n",
        "                embeddings.append(embedding)\n",
        "                print(\n",
        "                    f\"   ‚úÖ Text {i+1}/{len(texts)}: Got embedding with {len(embedding)} dimensions\"\n",
        "                )\n",
        "            else:\n",
        "                print(f\"   ‚ùå Text {i+1}/{len(texts)}: Invalid response structure\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Text {i+1}/{len(texts)}: Error getting embedding: {e}\")\n",
        "            return None\n",
        "\n",
        "    if len(embeddings) == len(texts):\n",
        "        print(f\"‚úÖ Successfully got embeddings for all {len(texts)} texts\")\n",
        "        return embeddings\n",
        "    else:\n",
        "        print(f\"‚ùå Mismatch: got {len(embeddings)} embeddings for {len(texts)} texts\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def custom_cosine_similarity(a, b):\n",
        "    \"\"\"\n",
        "    Custom cosine similarity calculation between two vectors\n",
        "\n",
        "    Args:\n",
        "        a, b: Input vectors\n",
        "\n",
        "    Returns:\n",
        "        Cosine similarity score (float)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        a = np.asarray(a, dtype=np.float64)\n",
        "        b = np.asarray(b, dtype=np.float64)\n",
        "\n",
        "        dot_product = np.dot(a, b)\n",
        "\n",
        "        norm_a = np.linalg.norm(a)\n",
        "        norm_b = np.linalg.norm(b)\n",
        "\n",
        "        if norm_a == 0 or norm_b == 0:\n",
        "            return 0.0\n",
        "\n",
        "        similarity = dot_product / (norm_a * norm_b)\n",
        "\n",
        "        return np.clip(similarity, -1.0, 1.0)\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "def calculate_cosine_similarities(query_embedding, question_embeddings):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between query and all questions\n",
        "\n",
        "    Args:\n",
        "        query_embedding: Embedding vector for the original keyword\n",
        "        question_embeddings: List of embedding vectors for generated questions\n",
        "\n",
        "    Returns:\n",
        "        List of similarity scores\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\n",
        "            f\"üßÆ Calculating cosine similarities for {len(question_embeddings)} questions...\"\n",
        "        )\n",
        "\n",
        "        similarities = []\n",
        "        for i, question_embedding in enumerate(question_embeddings):\n",
        "            similarity = custom_cosine_similarity(query_embedding, question_embedding)\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        similarities = np.array(similarities)\n",
        "\n",
        "        print(f\"   ‚úÖ Calculated {len(similarities)} similarities\")\n",
        "        print(\n",
        "            f\"   üìä Similarity range: {similarities.min():.3f} to {similarities.max():.3f}\"\n",
        "        )\n",
        "        print(f\"   üìä Mean similarity: {similarities.mean():.3f}\")\n",
        "\n",
        "        return similarities\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error calculating similarities: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def query_fanout(keyword, language, top_n=5):\n",
        "    \"\"\"\n",
        "    Generate 10 semantically related questions using Gemini 2.5 PRO,\n",
        "    then rank them using embeddings and cosine similarity to return top N\n",
        "\n",
        "    Args:\n",
        "        keyword: The keyword to analyze\n",
        "        language: Language for the query fanout process\n",
        "        top_n: Number of top questions to return (1-10, default 5)\n",
        "\n",
        "    Returns:\n",
        "        List of top N questions ranked by relevance, or None if failed\n",
        "    \"\"\"\n",
        "    # Validate top_n\n",
        "    top_n = max(1, min(10, top_n))\n",
        "\n",
        "    api_key = get_gemini_api_key()\n",
        "    if not api_key:\n",
        "        return None\n",
        "\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent?key={api_key}\"\n",
        "\n",
        "    system_prompt = \"\"\"You are an advanced AI search assistant. Your task is to use the \"query fan-out\" technique to anticipate a user's complete informational need from a single keyword.\n",
        "\n",
        "You will generate a list of 10 highly semantically related and comprehensive short questions that a user might have based on this keyword.\n",
        "\n",
        "To generate these questions, follow this process:\n",
        "\n",
        "1. Analyze the Core Keyword: Identify the central subject and any implied context of <keyword>.\n",
        "\n",
        "2. Fan-Out by Intent: Brainstorm questions based on different user goals. Consider if the user might be trying to:\n",
        "   - Learn (What is...?)\n",
        "   - Compare (X vs. Y)\n",
        "   - Find (Where can I...?)\n",
        "   - Troubleshoot (How to fix...?)\n",
        "   - And other potential intents\n",
        "\n",
        "3. Fan-Out by Sub-Topic: Break <keyword> into its essential components or related facets.\n",
        "\n",
        "4. Anticipate Next Steps: Think about what a user would logically ask after getting a basic answer to their initial query about <keyword>.\n",
        "\n",
        "5. Synthesize: Formulate 10 distinct, insightful short questions based on your analysis.\n",
        "\n",
        "After completing your analysis, provide your output in a structured JSON format.\n",
        "\n",
        "The JSON should contain an array named \"questions\" with 10 string elements, each representing one of your generated short semantically related question.\n",
        "\n",
        "Your final output should look like this:\n",
        "\n",
        "{\n",
        "  \"questions\": [\n",
        "    \"Question 1\",\n",
        "    \"Question 2\",\n",
        "    \"Question 3\",\n",
        "    \"Question 4\",\n",
        "    \"Question 5\",\n",
        "    \"Question 6\",\n",
        "    \"Question 7\",\n",
        "    \"Question 8\",\n",
        "    \"Question 9\",\n",
        "    \"Question 10\"\n",
        "  ]\n",
        "}\n",
        "\n",
        "Remember, your final output should only include the JSON structure.\n",
        "\n",
        "Do not include your inner monologue or any other text in the final output.\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"The keyword you will analyze is:\n",
        "<keyword>\n",
        "{keyword}\n",
        "</keyword>\n",
        "\n",
        "Language of keyword, operation and output language:\n",
        "<language>\n",
        "{language}\n",
        "</language>\"\"\"\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": [{\"parts\": [{\"text\": system_prompt}, {\"text\": user_prompt}]}],\n",
        "        \"generationConfig\": {\n",
        "            \"temperature\": 0.7,\n",
        "            \"topK\": 40,\n",
        "            \"topP\": 0.95,\n",
        "            \"maxOutputTokens\": 2048,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    try:\n",
        "        print(f\"üîç Generating query fanout for keyword: '{keyword}' in {language}...\")\n",
        "        print(f\"üéØ Will return top {top_n} results\")\n",
        "        response = requests.post(url, headers=headers, json=payload, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        result = response.json()\n",
        "\n",
        "        if \"candidates\" in result and len(result[\"candidates\"]) > 0:\n",
        "            content = result[\"candidates\"][0][\"content\"]\n",
        "            if \"parts\" in content and len(content[\"parts\"]) > 0:\n",
        "                text_response = content[\"parts\"][0][\"text\"]\n",
        "\n",
        "                text_response = text_response.strip()\n",
        "                if text_response.startswith(\"```json\"):\n",
        "                    text_response = text_response[7:]\n",
        "                if text_response.startswith(\"```\"):\n",
        "                    text_response = text_response[3:]\n",
        "                if text_response.endswith(\"```\"):\n",
        "                    text_response = text_response[:-3]\n",
        "                text_response = text_response.strip()\n",
        "\n",
        "                try:\n",
        "                    questions_data = json.loads(text_response)\n",
        "                    if \"questions\" in questions_data:\n",
        "                        questions = questions_data[\"questions\"]\n",
        "                        print(f\"‚úÖ Successfully generated {len(questions)} questions\")\n",
        "\n",
        "                        print(\n",
        "                            f\"\\nüéØ Ranking questions using Google embeddings and cosine similarity...\"\n",
        "                        )\n",
        "\n",
        "                        all_texts = [keyword] + questions\n",
        "                        embeddings = get_gemini_embeddings(all_texts, api_key)\n",
        "\n",
        "                        if embeddings and len(embeddings) == len(all_texts):\n",
        "                            query_embedding = embeddings[0]\n",
        "                            question_embeddings = embeddings[1:]\n",
        "\n",
        "                            similarities = calculate_cosine_similarities(\n",
        "                                query_embedding, question_embeddings\n",
        "                            )\n",
        "\n",
        "                            if similarities is not None:\n",
        "                                similarity_results = [\n",
        "                                    (i, sim, questions[i])\n",
        "                                    for i, sim in enumerate(similarities)\n",
        "                                ]\n",
        "                                similarity_results.sort(\n",
        "                                    key=lambda x: x[1], reverse=True\n",
        "                                )\n",
        "\n",
        "                                print(\n",
        "                                    f\"\\nüèÜ Top {top_n} ranked questions by similarity:\"\n",
        "                                )\n",
        "                                for i, (idx, sim, question) in enumerate(\n",
        "                                    similarity_results[:top_n]\n",
        "                                ):\n",
        "                                    print(\n",
        "                                        f\"   {i+1}. [similarity: {sim:.3f}] {question}\"\n",
        "                                    )\n",
        "\n",
        "                                top_questions = [\n",
        "                                    question\n",
        "                                    for _, _, question in similarity_results[:top_n]\n",
        "                                ]\n",
        "                                return top_questions\n",
        "                            else:\n",
        "                                print(\n",
        "                                    f\"‚ùå Failed to calculate similarities, returning top {top_n} questions unranked\"\n",
        "                                )\n",
        "                                return questions[:top_n]\n",
        "                        else:\n",
        "                            print(\n",
        "                                f\"‚ùå Failed to get embeddings, returning top {top_n} questions unranked\"\n",
        "                            )\n",
        "                            return questions[:top_n]\n",
        "                    else:\n",
        "                        print(\"‚ùå Error: Response doesn't contain 'questions' field\")\n",
        "                        return None\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"‚ùå Error parsing JSON response: {e}\")\n",
        "                    print(f\"Response text: {text_response[:500]}...\")\n",
        "                    return None\n",
        "\n",
        "        print(\"‚ùå Error: Invalid response structure from Gemini API\")\n",
        "        return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Error calling Gemini API: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function for interactive use in Google Colab\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ü§ñ Gemini Query Fanout - Powered by Gemini\")\n",
        "    print(\"üéØ Returns Top N Questions Ranked by Cosine Similarity\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    keyword = input(\"Enter keyword: \").strip()\n",
        "    if not keyword:\n",
        "        print(\"‚ùå Keyword cannot be empty!\")\n",
        "        return\n",
        "\n",
        "    language = input(\"Enter language (e.g., English, Polish, Spanish): \").strip()\n",
        "    if not language:\n",
        "        print(\"‚ùå Language cannot be empty!\")\n",
        "        return\n",
        "\n",
        "    # Get number of results\n",
        "    top_n_input = input(\"Enter number of results to return (1-10, default 5): \").strip()\n",
        "    if top_n_input:\n",
        "        try:\n",
        "            top_n = int(top_n_input)\n",
        "            top_n = max(1, min(10, top_n))\n",
        "        except ValueError:\n",
        "            print(\"‚ö†Ô∏è Invalid number, using default (5)\")\n",
        "            top_n = 5\n",
        "    else:\n",
        "        top_n = 5\n",
        "\n",
        "    print()\n",
        "\n",
        "    questions = query_fanout(keyword, language, top_n)\n",
        "\n",
        "    if questions:\n",
        "        print()\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"üìù Top {len(questions)} Questions (Ranked by Relevance):\")\n",
        "        print(\"=\" * 60)\n",
        "        for i, question in enumerate(questions, 1):\n",
        "            print(f\"{i}. {question}\")\n",
        "        print()\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"üìã JSON Output:\")\n",
        "        print(\"=\" * 60)\n",
        "        print(json.dumps({\"questions\": questions}, indent=2, ensure_ascii=False))\n",
        "    else:\n",
        "        print(\n",
        "            \"‚ùå Failed to generate questions. Please check your API key and try again.\"\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StLxnfoziz5V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
